<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Hi, Jon Here. Please DELETE the two <script> tags below if you use this HTML, otherwise my analytics will track your page -->
  <!-- Global site tag (gtag.js) - Google Analytics -->

  <title>Aman Raj</title>
  
  <meta name="author" content="Rechita Singh">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images2/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rechita Singh</name>
              </p>
              <p align="justify">I am <b> a Data Enthusiast! Currently enrolled in MSBA - specializing in Data Science </b>  at <a href="https://www.utdallas.edu/h">UTD </a>. Here, I have build my foundations on Advance Machine Learning, Deep Learning, and Natural Language Models, demonstrating a GPA of 4.0 and awarded with the competitive scholarship for two semesters.
              <p align="justify">
                During the summer, I was presented with the opportunity to work as a Data Science Intern at <a href="https://www.brevanhoward.com/h"> Brevan Howard </a>, where my skillset of Python, Advance Statistics, and Machine Learning were further solidified. Additionally, working & researching in the commodity market along with analyzing global macroeconomic flows using platforms like Bloomberg made me eqipped for financial data. 
               </p>
               <p align="justify">
                 After completing my undergraduate studies in B.Tech from <a href="http://dtu.ac.in/"> Delhi Technological University</a>, I worked as <b> Software Engineer </b> at Facebook and <b> Research Intern </b> at Samsung Labs. My research work has received notable awards such as <a href="https://www.isprs.org/society/awards/dangermond.aspx"> The Jack Dangermond Award â€“ Best Paper</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:amanrajdce@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data2/AmanRaj_CV.pdf">CV</a> &nbsp/&nbsp
               <!-- <a href="data2/AmanRaj-bio.txt">Biography</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.co.in/citations?user=sdgrTYEAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/amanrajdce">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/amanrajdce/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="data2/head_low.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="data2/head_low_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table width="50%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td > <img src="images2/apple.png"></td>
            <td > <img src="images2/facebook.png"></td>
            <td > <img src="images2/samsung.png"></td>
          </tr>
        </tbody> </table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p> My research interests are in computer vision, machine learning and optimization, and image processing. The majority of my research is about image and video understanding.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr onmouseout="thesis_stop()" onmouseover="thesis_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_image3'><img src='images2/ucsd_ms_thesis_after.png' alt="Boundary_png" style="border-style: none" width="190" height="150"></div>
                <img src='images2/ucsd_ms_thesis_before.png' alt="Boundary_png" style="border-style: none" width="190" height="150">
              </div>
              <script type="text/javascript">
                function thesis_start() {
                  document.getElementById('ccc_image3').style.opacity = "1";
                }

                function thesis_stop() {
                  document.getElementById('ccc_image3').style.opacity = "0";
                }
                thesis_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="https://escholarship.org/uc/item/1p85x50q">
                <papertitle>Learning Augmentation Policy Schedules for Unsuperivsed Depth Estimation.</papertitle>
              </a>
              <br>
              <strong>Aman Raj</strong>
              <br>
              <em>UC San Diego Electronic Theses and Dissertations, 2020 </em>
              <br>
              <a href="data2/AmanRaj_MS_Thesis_UCSD.pdf">thesis</a> / <a href="https://github.com/amanrajdce/laps-depth">code</a>
              <p> My MS thesis that proposes a novel approach to augment data for unsupervised depth estimation. Our method learn data augmentation strategies from data itself.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images2/suw_cvpr2020.png" alt="Boundary_png" style="border-style: none" width="190" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w45/Ren_SUW-Learn_Joint_Supervised_Unsupervised_Weakly_Supervised_Deep_Learning_for_Monocular_CVPRW_2020_paper.pdf">
                <papertitle>SUW-Learn: Joint Supervised, Unsupervised, Weakly Supervised Deep Learning for Monocular Depth Estimation.</papertitle>
              </a>
              <br>
              Haoyu Ren, <strong>Aman Raj</strong>, Mostafa El-Khamy and Jungwon Lee
              <br>
              <em>CVPR</em>, 2020
              <br>
              <a href="https://www.youtube.com/watch?v=jVaC34tloIU">video</a> / <a href="https://openaccess.thecvf.com/content_CVPRW_2020/supplemental/Ren_SUW-Learn_Joint_Supervised_CVPRW_2020_supplemental.pdf">supplement</a>
              <p> A framework for deep-learning with joint supervised learning (S), unsupervised learning (U), and weakly-supervised learning (W). We deploy SUW- Learn for deep learning of the monocular depth from im- ages and video sequences.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images2/signet.png" alt="Boundary_png" style="border-style: none" width="190" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Meng_SIGNet_Semantic_Instance_Aided_Unsupervised_3D_Geometry_Perception_CVPR_2019_paper.pdf">
                <papertitle>SIGNet: Semantic Instance Aided Unsupervised 3D Geometry Perception.</papertitle>
              </a>
              <br>
              Yue Meng, Yongxi Lu, <strong>Aman Raj</strong>, Samuel Sunarjo, Rui Guo, Tara Javidi, Gaurav Bansal, <br> Dinesh Bharadia
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://mengyuest.github.io/SIGNet/">project</a> / <a href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Meng_SIGNet_Semantic_Instance_CVPR_2019_supplemental.pdf">supplement</a>
              <p> SIGNet integrates semantic information to make depth and flow predictions consistent with objects and robust to low lighting conditions. SIGNet is shown to improve upon the state-of-the-art unsupervised learning for depth prediction.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images2/robocodes_cvpr2018.png" alt="Boundary_png" style="border-style: none" width="190" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://research.fb.com/wp-content/uploads/2018/06/A-Holistic-Framework-for-Addressing-the-World-using-Machine-Learning.pdf">
                <papertitle>A Holistic Framework for Addressing the World using Machine Learning.</papertitle>
              </a>
              <br>
              Ilke Demir, Forest Hughes, <strong>Aman Raj</strong>, Kaunil Dhruv, Suryanarayana Murthy Muddla, Sanyam Garg, Barrett Doo, Ramesh Raskar
              <br>
              <em>CVPR</em>, 2018
              <br>
              <a href="https://research.fb.com/publications/a-holistic-framework-for-addressing-the-world-using-machine-learning/">project</a>
              <p>We propose an automatic generative algorithm to create street addresses from satellite imagery. Our addressing scheme is coherent with the street topology, linear and hierarchical to follow human perception, and universal to be used as a unified geocoding system.</p>
            </td>
          </tr>

          <tr onmouseout="ccc_stop()" onmouseover="ccc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_image1'><img src='images2/isprs2018_after.png' alt="Boundary_png" style="border-style: none" width="190" height="90"></div>
                <img src='images2/isprs2018_before.png' alt="Boundary_png" style="border-style: none" width="190" height="90">
              </div>
              <script type="text/javascript">
                function ccc_start() {
                  document.getElementById('ccc_image1').style.opacity = "1";
                }

                function ccc_stop() {
                  document.getElementById('ccc_image1').style.opacity = "0";
                }
                ccc_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.mdpi.com/2220-9964/7/3/84/htm">
                <papertitle>Generative Street Addresses from Satellite Imagery.</papertitle>
              </a>
              <br>
              Ilke Demir, Forest Hughes, <strong>Aman Raj</strong>, Kaunil Dhruv, Suryanarayana Murthy Muddla, Sanyam Garg, Barrett Doo, Ramesh Raskar
              <br>
              <em>ISPRS</em>, 2018 &nbsp <font color="red"><strong>(The Jack Dangermond Award â€“ Best Paper)</strong></font>
              <br>
              <a href="https://research.fb.com/publications/generative-street-addresses-from-satellite-imagery/">project</a> / <a href="https://github.com/facebookresearch/street-addresses">code</a> / <a href="https://2017.stateofthemap.us/program/generative-street-addresses.html"> talk </a>
              <p>Our algorithm starts with extracting roads from satellite imagery by utilizing deep learning. Then, it uniquely labels the regions, roads, and structures using graph and proximity-based algorithms.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images2/robocodes_cvpr2017.png" alt="Boundary_png" style="border-style: none" width="190" height="60">
            </td>
            <td width="75%" valign="middle">
              <a href="https://research.fb.com/wp-content/uploads/2017/07/cvpr_ev_final_sent.pdf?">
                <papertitle>Robocodes: Towards Generative Street Addresses from Satellite Imagery.</papertitle>
              </a>
              <br>
              Ilke Demir, Forest Hughes, <strong>Aman Raj</strong>, Kleovoulos Tsourides, Divyaa Ravichandran, Suryanarayana Murthy, Kaunil Dhruv, Sanyam Garg, Jatin Malhotra, Barrett Doo, Grace Kermani, Ramesh Raskar
              <br>
              <em>CVPR</em>, 2017 &nbsp <font color="red"><strong>(Best Paper Award)</strong></font>
              <br>
              <a href="https://research.fb.com/publications/robocodes-towards-generative-street-addresses-from-satellite-imagery/">project</a> / <a href="https://github.com/facebookresearch/street-addresses">code</a> / <a href="https://research.fb.com/advancing-computer-vision-technologies-at-cvpr-2017/"> blog </a> / <a href="https://www.geospatialworld.net/blogs/mapping-unmapped-facebook-mit-project/"> news </a>
              <p>We describe our automatic generative algorithm to create street addresses (Robocodes) from satellite images by learning and labeling regions, roads, and blocks.</p>
            </td>
          </tr>

          <tr onmouseout="fpga_stop()" onmouseover="fpga_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_image2'><img src='images2/fpga_after.png' alt="Boundary_png" style="border-style: none" width="190" height="90"></div>
                <img src='images2/fpga_before.png' alt="Boundary_png" style="border-style: none" width="190" height="90">
              </div>
              <script type="text/javascript">
                function fpga_start() {
                  document.getElementById('ccc_image2').style.opacity = "1";
                }

                function fpga_stop() {
                  document.getElementById('ccc_image2').style.opacity = "0";
                }
                fpga_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="data2/fpga_icctict_2016.pdf">
                <papertitle>FPGA Accelerated Abandoned Object Detection.</papertitle>
              </a>
              <br>
              Rajesh Rohilla, <strong>Aman Raj</strong>, Saransh Kejriwal, Rajiv Kapoor
              <br>
              <em>ICCTICT, IEEE</em> 2016
              <br>
              <a href="data2/icctict_2016.pdf">slides</a>
              <p> We propose a hardware implementation of abandoned object detection algorithm on FPGA aimed for making a custom chip that can do real-time inference on live video feed.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images2/cmu_result.png" alt="Boundary_png" style="border-style: none" width="190" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="data2/CMU-RI-TR-AmanRaj.pdf">
                <papertitle>Multi-Scale Convolutional Architecture for Semantic Segmentation.</papertitle>
              </a>
              <br>
              <strong>Aman Raj</strong>, Daniel Maturana, Sebastian Scherer
              <br>
              <em>RI Technical Reports, CMU</em> 2015
              <br>
              <a href="https://www.ri.cmu.edu/publications/multi-scale-convolutional-architecture-for-semantic-segmentation/">project</a> / <a href="data2/cmu_slides.pdf">slides</a>
              <p> This work exploits the geocentric encoding of a depth image and uses a multi-scale deep convolutional neural network architecture that captures high and low- level features of a scene to generate rich semantic labels.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images2/icvgip2014.png" alt="Boundary_png" style="border-style: none" width="190" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="data2/ICVGIP_2014.pdf">
                <papertitle>Digitization of Historic Inscription Images using Cumulants based Simultaneous Blind Source Extraction.</papertitle>
              </a>
              <br>
              N. Jayanthi, Ayush Tomar, <strong>Aman Raj</strong>, S. Indu, Santanu Chaudhury
              <br>
              <em>ICVGIP </em> 2014
              <br>
              <p> Proposed technique provides a suitable method to separate the text layer from the historic inscription images by considering the problem as blind source separation which aims to calculate the independent components from a linear mixture of source signals, by maximizing a contrast function based on higher order cumulants.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images2/accv2014.png" alt="Boundary_png" style="border-style: none" width="190" height="130">
            </td>
            <td width="75%" valign="middle">
              <a href="data2/ACCV_2014.pdf">
                <papertitle>Enhancement and Retrieval of Historic Inscription Images.</papertitle>
              </a>
              <br>
              S. Indu, Ayush Tomar, <strong>Aman Raj</strong>, Santanu Chaudhury
              <br>
              <em>ACCV </em> 2014
              <br>
              <p> Binarization of inscription images using the proposed cumulants based Blind Source Extraction(BSE) method, and store them in a digital library
                with their corresponding historic information which can be retrieved later using image retrieval algorithms such as BoW.</p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Patents</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td width="75%" valign="middle">
              <a href="https://patentimages.storage.googleapis.com/a1/45/ec/2bdb1b2faadf96/US20210124985A1.pdf">
                <papertitle>System and Method for Deep Machine Learning for Computer Vision Applications </papertitle>
              </a>
              <br>
              US20210124985A1, US20220391632A1
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Miscellaneous</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images2/ucsd_lib_logo.png" style="border-style: none" width="130" height="130"></td>
            <td width="75%" valign="center">
              <a href="https://sites.google.com/eng.ucsd.edu/cse12spring/home">Teaching Assistant, CSE 12 - Spring 2019</a>
              <br>
            </td>
          </tr>
          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images2/velo.png" alt="Boundary_png" style="border-style: none" width="190" height="130">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vimeo.com/149376920">
                <papertitle>Velo</papertitle>
              </a>
              <p> As Data Scientist at SupplyAI Inc. developed predictive intelligent models for logistics in supply chain. Models that allocates shipper for a particular order, predicts various delays in delivering it, estimating pickup date of order by shipper, predicting returns on orders. </p>
            </td>
          </tr> -->
          <tr onmouseout="comic_stop()" onmouseover="comic_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_comic'><img src='images2/comic_polyglot_after.png' alt="Boundary_png" style="border-style: none" width="190" height="130"></div>
                <img src='images2/comic_polyglot_before.png' alt="Boundary_png" style="border-style: none" width="190" height="130">
              </div>
              <script type="text/javascript">
                function comic_start() {
                  document.getElementById('ccc_comic').style.opacity = "1";
                }

                function comic_stop() {
                  document.getElementById('ccc_comic').style.opacity = "0";
                }
                comic_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="data2/comicpolyglot.pdf">
                <papertitle>Comic Polyglot</papertitle>
              </a>
              <br>
              <em>CMU Winter School, 2014 </em> &nbsp <font color="red"><strong>(Best Project Award)</strong></font>
              <br>
              <a href="data2/comicpolyglot.pdf">poster</a>
              <p> Comic Polyglot-A system that identifies the text regions in comic strips like Manga and subsequently translates itâ€™s Japanese text into English using an OCR engine while maintaining the syntax. It is aimed to help English-speaking manga comic readers. </p>
            </td>
          </tr>
          <tr onmouseout="luna_stop()" onmouseover="luna_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_luna'><img src='images2/lunabot_after.png' alt="Boundary_png" style="border-style: none" width="190" height="130"></div>
                <img src='images2/lunabot_before.png' alt="Boundary_png" style="border-style: none" width="190" height="130">
              </div>
              <script type="text/javascript">
                function luna_start() {
                  document.getElementById('ccc_luna').style.opacity = "1";
                }

                function luna_stop() {
                  document.getElementById('ccc_luna').style.opacity = "0";
                }
                luna_stop()
              </script>
            </td>
            <td width="75%" valign="middle">
              <a href="data2/lunabot_photos.pdf">
                <papertitle>Lunabot</papertitle>
              </a>
              <br>
              <em>NASA's Lunabotics Mining Competition, 2013</em>
              <br>
              <a href="data2/lunabot_sys_eng_paper.pdf">paper</a> / <a href="data2/lunabot_outreach.pdf">outreach</a> / <a href="data2/lunabot_photos.pdf">gallery</a>
              <p>Aaravya Lunabot - DTUâ€™s official entry into NASA Lunabotics Mining Competition 2013. The challenge required student teams to design and build a mining robot that can traverse the simulated lunar chaotic terrain, excavate lunar regolith and deposit the regolith into a collector bin within ten minutes. </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
               Website design from  <a href="https://jonbarron.info/">here</a>

              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
